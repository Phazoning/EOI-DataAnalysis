{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ea14cb",
   "metadata": {},
   "source": [
    "![penguins](https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3104df",
   "metadata": {},
   "source": [
    "https://github.com/allisonhorst/palmerpenguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fddcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "penguins = pd.read_csv(\"penguins.csv\")\n",
    "\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88490ca6",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015e7fc",
   "metadata": {},
   "source": [
    "To check column datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penguins[e].dtype for e in penguins.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2783b7",
   "metadata": {},
   "source": [
    "To summarize: \n",
    "\n",
    "\n",
    "species - cualitative\n",
    "\n",
    "island - cualitative\n",
    "\n",
    "bill_length_mm - real cuantitative\n",
    "\n",
    "bill_depth_mm - real cuantitative\n",
    "\n",
    "flipper_length_mm - real cuantitative\n",
    "\n",
    "body_mass_g - real cuantitative\n",
    "\n",
    "sex - cualitative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56d56d",
   "metadata": {},
   "source": [
    "Class unbalance: \n",
    "\n",
    "We'll turn our attention to cualitative classes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "[penguins[e].value_counts() for e in penguins.columns if not is_numeric_dtype(penguins[e].dtype)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c7913",
   "metadata": {},
   "source": [
    "As we can see, there's no heavy unbalance except on the case of the island, where we have quite the mayhem because an insland only takes slightly more than the 10% of the total registries\n",
    "\n",
    "Before getting on the variable itself, it's worth noting something: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c75b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{penguins[penguins.island == e].species.value_counts().index} on island {e}\" for e in penguins.island.value_counts().index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a975f8",
   "metadata": {},
   "source": [
    "As we can see, only a single species inhabits the three islands, which might not match reality, as penguins are pretty nomadic (worse in the case of the Gentoo species, which are barely territorial),, so we can drop this variable down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.drop(axis=1, columns=\"island\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a87ed4",
   "metadata": {},
   "source": [
    "Variable exploration\n",
    "\n",
    "Now, onto the variables themselves. First we want to see if there's any correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(penguins.corr(), annot=True, cbar=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53739a51",
   "metadata": {},
   "source": [
    "As we can see, the flipper length is heavily correlated with the weight, so we can drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.drop(axis=1, columns=\"flipper_length_mm\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e5844",
   "metadata": {},
   "source": [
    "Variations due to sexual dimorphism can be an issue, depending on how heavy they are, but as we can see in the following graphics, there are heavy, clear differences between the two sexes (instead of every individual being more centered on the average, no matter of the gender, which would us allow to drop it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show([sns.pairplot(penguins[penguins.species == e], hue='sex') for e in penguins.species.value_counts().index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750a1c9",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "First of all, we'll seek all registries with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"Percent of not nulls in column {e} is {len([i for i in penguins[e].notnull() if i])/len(penguins)}\" for e in penguins.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b461fb0",
   "metadata": {},
   "source": [
    "As you can see, on average, the percent of null fields is quite small, so we can get rid of all of them right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf12a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412637f7",
   "metadata": {},
   "source": [
    "Now we get into muddy terrain. Here we used for the standard deviation zero degrees of freedom (ddof), as we are assuming our set to be a population, not a sample, thus forcing it to take zero instead of the default one.\n",
    "\n",
    "Heavy variations of the standard deviation with the average mightmark the presence of outliers (as a quick reference), so we shall do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "[f\"Column {e} variation is {penguins[e].std(ddof=0)/penguins[e].mean()}\" for e in penguins.columns if is_numeric_dtype(penguins[e].dtype)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f169e",
   "metadata": {},
   "source": [
    "Every column is within normalcy except for the body mass one. As such, we must proceed with further analysis. For this we use the z-score, which for a certain value marks how many times the standard deviation is that value deviated from the average. Example gratia, a z-score of 2, would mean that the value minus the average is twice the standard deviation.\n",
    "\n",
    "Also, outliers appear as greater or equal to three times the standard deviation or lesser or equal to minus three times the standard deviation. We can simplify it by saying that its absolute z-score is greater or equal to three. Now, let's check the evolution of the (absolute) z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "mass = penguins.mass\n",
    "\n",
    "for e in np.arange(0., 3., 0.25):\n",
    "    print(f\"Number of elements over {e} times the deviation is {len([i for i in abs(zscore(mass, ddof=0)) if i > e])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb5f85",
   "metadata": {},
   "source": [
    "As we can see, there's no values with an z-score greater than or equal to three, so there are no outliers. Plus, its evolution is pretty good, following the trace of a normal distribution, so it is due to the scale of the value. We can correcting it by normalizing the values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as prepro\n",
    "\n",
    "normalizer = prepro.Normalizer(norm='l1')\n",
    "norm_mass = normalizer.fit_transform(mass.values.reshape(1, -1))[0]\n",
    "\n",
    "penguins[\"body_mass_g\"] = norm_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4940cf",
   "metadata": {},
   "source": [
    "To end the preprocessing, we will convert all cualitative columns into labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ce244",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = penguins.species\n",
    "sex = penguins.sex\n",
    "\n",
    "le = prepro.LabelEncoder\n",
    "\n",
    "species_labeled = le.fit_transform(le, y=species)\n",
    "penguins.species = species_labeled\n",
    "\n",
    "sex_labeled = le.fit_transform(le, y=sex)\n",
    "penguins.sex = sex_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891042a",
   "metadata": {},
   "source": [
    "Now onto the models.\n",
    "\n",
    "\n",
    "Before we get into it we'll fetch the basics, plus a pretty nifty function to give us a degree of commodity. Said function will tell us straight away the accuracy of our model and the confusion matrix (which tells us how many positives on the predictions have scored/missed the mark)\n",
    "\n",
    "We'll also set the basic sets for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccacd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report, confusion_matrix\n",
    "\n",
    "def show_metrics(clf, y_test, y_pred):\n",
    "    print(f'Accuracy score: {int(accuracy_score(y_test, y_pred)*100)}%\\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test)\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = penguins.drop(\"species\", axis=1)\n",
    "Y = penguins.species.values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=73)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e46bc",
   "metadata": {},
   "source": [
    "Now, this is a classification problem (we want to give a label to new  data). Given the map the guys at sklearn kindly give to us (https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), we'll choose a linear support vector column model, given that we have prelabeled data and our set is greater than 100 entries. Allow us to train the model, and check the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc332faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "linear_svc = SVC(gamma='auto')\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = linear_svc.predict(X_test)\n",
    "show_metrics(linear_svc, Y_test, Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd44ebf",
   "metadata": {},
   "source": [
    "Which, as we can see has a good precision with an acceptable confusion matrix.\n",
    "\n",
    "Now, we want to check how effective was this, so we do cross-validation tests with different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "[print(i) for i in [cross_val_score(SVC(kernel=e, C=1, random_state=73), X, Y, cv=5) for e in ['linear', 'rbf', 'poly']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68898d7d",
   "metadata": {},
   "source": [
    "Which gives us pretty good results for the linear one, somewhat good for the rfb and plainly good on the polynomial. As such, our model is well defined, although open to improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
